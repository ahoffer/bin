#!/bin/bash
# llmexplore: Ollama-powered codebase exploration
# Usage: llmexplore "what files handle authentication?"
#
# This tool runs grep/find/cat commands via Ollama and returns
# only the final answer, reducing Claude's context usage.

set -euo pipefail

DEBUG="${LLM_EXPLORE_DEBUG:-}"

if [[ $# -eq 0 ]]; then
    echo "Usage: llmexplore <question about the codebase>"
    echo "Example: llmexplore 'where is authentication handled?'"
    echo ""
    echo "Environment:"
    echo "  LLM_EXPLORE_DEBUG=1  - Show debug output"
    echo "  OLLAMA_MODEL_CHAT=... - Override model (default: llama3.2:latest)"
    echo "  OLLAMA_HOST=...      - Override host (default: http://bigfish:11434)"
    exit 1
fi

source "$(dirname "$0")/ollamalib.sh"
ollama_require

QUERY="$*"
MAX_ITERATIONS=5

debug() {
    [[ -n "$DEBUG" ]] && echo "[DEBUG] $*" >&2
}

# Detect project type for context
PROJECT_CONTEXT=""
if [[ -f pom.xml ]]; then
    PROJECT_CONTEXT="This is a Java/Maven project."
elif [[ -f package.json ]]; then
    PROJECT_CONTEXT="This is a JavaScript/Node.js project."
elif [[ -f Cargo.toml ]]; then
    PROJECT_CONTEXT="This is a Rust project."
elif [[ -f go.mod ]]; then
    PROJECT_CONTEXT="This is a Go project."
elif [[ -f setup.py || -f pyproject.toml ]]; then
    PROJECT_CONTEXT="This is a Python project."
fi

# System prompt - very explicit about format
read -r -d '' SYSTEM_PROMPT_TEMPLATE << 'SYSPROMPT' || true
You explore codebases by running shell commands. You MUST use this EXACT format:

To run a command, output a line starting with "CMD:" followed by the command:
CMD: grep -r "pattern" .

To give your final answer, output a line starting with "ANSWER:" followed by your answer:
ANSWER: The files are located in src/auth/ directory.

RULES:
- Output ONLY "CMD:" or "ANSWER:" lines, nothing else
- Use simple commands: grep -r, find -name, cat, head -50
- Limit file reads: use head -50 for large files
- Give concise answers (2-4 sentences)
- If first command gives no results, try different patterns
- Start with grep -r to find relevant files, then read specific files
SYSPROMPT

SYSTEM_PROMPT="$SYSTEM_PROMPT_TEMPLATE

$PROJECT_CONTEXT"

CONTEXT=""

for ((i=1; i<=MAX_ITERATIONS; i++)); do
    debug "Iteration $i of $MAX_ITERATIONS"

    # Build the prompt
    if [[ -z "$CONTEXT" ]]; then
        PROMPT="Find: $QUERY

What command should I run? Remember: output must start with CMD: or ANSWER:"
    else
        PROMPT="Find: $QUERY

Context from previous commands:
$CONTEXT

Based on these results, what next? Output CMD: for another command or ANSWER: with your conclusion."
    fi

    debug "Calling Ollama..."
    RESPONSE=$(ollama_generate "$MODEL_CHAT" "$PROMPT" "$SYSTEM_PROMPT")

    if [[ -z "$RESPONSE" ]]; then
        echo "Error: No response from Ollama" >&2
        exit 1
    fi

    debug "Response: $RESPONSE"

    # Look for ANSWER: pattern (case insensitive, may have leading text)
    if echo "$RESPONSE" | grep -qiE '(^|[^A-Z])ANSWER:'; then
        # Extract everything after ANSWER:
        ANSWER=$(echo "$RESPONSE" | sed -n 's/.*[Aa][Nn][Ss][Ww][Ee][Rr]: *//p' | head -5)
        if [[ -n "$ANSWER" ]]; then
            echo "$ANSWER"
            exit 0
        fi
    fi

    # Look for CMD: pattern
    if echo "$RESPONSE" | grep -qiE '(^|[^A-Z])CMD:'; then
        CMD=$(echo "$RESPONSE" | grep -oiP 'CMD:\s*\K.*' | head -1 | xargs)

        if [[ -z "$CMD" ]]; then
            debug "Empty command extracted"
            continue
        fi

        debug "Running: $CMD"

        # Safety check - no destructive commands
        if echo "$CMD" | grep -qE '(rm |mv |chmod|chown|>|>>|sudo)'; then
            echo "Error: Unsafe command blocked: $CMD" >&2
            exit 1
        fi

        # Run the command, capture output (limit to 100 lines)
        OUTPUT=$(timeout 10s bash -c "$CMD" 2>&1 </dev/null | head -100 || echo "(command failed or timed out)")

        # Truncate very long outputs
        if [[ ${#OUTPUT} -gt 5000 ]]; then
            OUTPUT="${OUTPUT:0:5000}... (truncated)"
        fi

        CONTEXT="$CONTEXT

\$ $CMD
$OUTPUT
"
        # Keep context manageable
        CONTEXT=$(echo "$CONTEXT" | tail -c 8000)
    else
        # Model gave a free-form response without CMD: or ANSWER:
        # Treat it as an answer if we've done at least one search
        if [[ -n "$CONTEXT" ]]; then
            echo "$RESPONSE"
            exit 0
        fi
        debug "No CMD: or ANSWER: found, retrying..."
    fi
done

# If we hit max iterations but have context, ask for final answer
FINAL_PROMPT="Based on these search results, give a brief answer to: $QUERY

$CONTEXT

Respond with ONLY your answer, no prefixes needed."

FINAL_SYSTEM="Give a concise 2-3 sentence answer based on the provided search results."

FINAL=$(ollama_generate "$MODEL_CHAT" "$FINAL_PROMPT" "$FINAL_SYSTEM")
if [[ -n "$FINAL" ]]; then
    echo "$FINAL"
    exit 0
fi

echo "Error: Could not find answer after $MAX_ITERATIONS iterations" >&2
exit 1
