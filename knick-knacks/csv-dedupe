#!/usr/bin/env python3
"""Remove duplicate rows from a security CSV based on package columns.

Deduplicates by: package_names, package_versions, fixed_versions
Outputs to <input_file>-deduped.csv (or specify output file as second arg)
"""

import csv
import sys
import os

def main():
    if len(sys.argv) < 2 or len(sys.argv) > 3:
        print(f"Usage: {sys.argv[0]} <input_csv> [output_csv]", file=sys.stderr)
        sys.exit(1)

    input_file = sys.argv[1]

    if len(sys.argv) == 3:
        output_file = sys.argv[2]
    else:
        base, ext = os.path.splitext(input_file)
        output_file = f"{base}-deduped{ext}"

    with open(input_file, 'r') as f:
        reader = csv.DictReader(f)
        fieldnames = reader.fieldnames
        rows = list(reader)

    seen = set()
    unique = []

    for row in rows:
        key = (row['package_names'], row['package_versions'], row['fixed_versions'])
        if key not in seen:
            seen.add(key)
            unique.append(row)

    with open(output_file, 'w', newline='') as f:
        writer = csv.DictWriter(f, fieldnames=fieldnames)
        writer.writeheader()
        writer.writerows(unique)

    dupes = len(rows) - len(unique)
    print(f"Original rows: {len(rows)}")
    print(f"Deduplicated rows: {len(unique)}")
    print(f"Removed: {dupes}")
    print(f"Output: {output_file}")

if __name__ == "__main__":
    main()
